{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5ac04a-d5c5-4d30-ac99-d2b511cbd019",
   "metadata": {},
   "source": [
    "# RNN-based clutch control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1772151e-fe7d-45e4-b6db-f2a8e8c44803",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from io import StringIO\n",
    "from contextlib import redirect_stdout\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d29be1-b18c-4b4e-b4ef-f7f20ce25e05",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba573f86-3589-48ae-963e-189a3da33439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../datasets/Thrust 2 Data Collections/Round 3 Raw/PS_004raw.csv :45_964 samples\n",
      "Reading ../datasets/Thrust 2 Data Collections/Round 3 Raw/PS_001raw.csv :80_000 samples\n",
      "Reading ../datasets/Thrust 2 Data Collections/Round 3 Raw/PS2_002raw.csv :61_922 samples\n",
      "Reading ../datasets/Thrust 2 Data Collections/Round 3 Raw/PS2_004raw.csv :61_922 samples\n",
      "Reading ../datasets/Thrust 2 Data Collections/Round 3 Raw/PS2_003raw.csv :60_502 samples\n",
      "Reading ../datasets/Thrust 2 Data Collections/Round 3 Raw/PS2_001raw.csv :43_871 samples\n",
      "Reading ../datasets/Thrust 2 Data Collections/Round 3 Raw/PS_002raw.csv :84_749 samples\n",
      "Reading ../datasets/Thrust 2 Data Collections/Round 3 Raw/PS_003raw.csv :113_407 samples\n",
      "total_samples = 552_337\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "dataset_dir = Path(\"../datasets/Thrust 2 Data Collections/Round 3 Raw\")\n",
    "total_samples = 0\n",
    "for data_file in dataset_dir.glob(\"*.csv\"):\n",
    "    print(f\"Reading {data_file} :\", end=\"\")\n",
    "    dfs[data_file.stem] = pd.read_csv(data_file)\n",
    "    n_samples = dfs[data_file.stem].shape[0]\n",
    "    print(f\"{n_samples:_} samples\")\n",
    "    total_samples += n_samples\n",
    "    \n",
    "print(f\"{total_samples = :_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc11889-7ab8-44a6-855d-5d5a112b9580",
   "metadata": {},
   "source": [
    "## Define study and CV experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002917b1-0cef-4e96-a6d1-f065282e356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study_name = 'Raw'\n",
      "study_features = ['PelvisGyro_x', 'PelvisGyro_y', 'PelvisGyro_z', 'PelvisAccel_X', 'PelvisAccel_Y', 'PelvisAccel_Z', 'T8Gyro_x', 'T8Gyro_y', 'T8Gyro_z', 'T8Accel_X', 'T8Accel_Y', 'T8Accel_Z', 'LeftThighGyro_x', 'LeftThighGyro_y', 'LeftThighGyro_z', 'LeftThighAccel_X', 'LeftThighAccel_Y', 'LeftThighAccel_Z', 'RightThighGyro_x', 'RightThighGyro_y', 'RightThighGyro_z', 'RightThighAccel_X', 'RightThighAccel_Y', 'RightThighAccel_Z']\n",
      "PS_004raw: [(80000, 24), (61922, 24), (61922, 24), (60502, 24), (43871, 24), (84749, 24), (113407, 24)] -> (45964, 24)\n",
      "PS_001raw: [(45964, 24), (61922, 24), (61922, 24), (60502, 24), (43871, 24), (84749, 24), (113407, 24)] -> (80000, 24)\n",
      "PS2_002raw: [(45964, 24), (80000, 24), (61922, 24), (60502, 24), (43871, 24), (84749, 24), (113407, 24)] -> (61922, 24)\n",
      "PS2_004raw: [(45964, 24), (80000, 24), (61922, 24), (60502, 24), (43871, 24), (84749, 24), (113407, 24)] -> (61922, 24)\n",
      "PS2_003raw: [(45964, 24), (80000, 24), (61922, 24), (61922, 24), (43871, 24), (84749, 24), (113407, 24)] -> (60502, 24)\n",
      "PS2_001raw: [(45964, 24), (80000, 24), (61922, 24), (61922, 24), (60502, 24), (84749, 24), (113407, 24)] -> (43871, 24)\n",
      "PS_002raw: [(45964, 24), (80000, 24), (61922, 24), (61922, 24), (60502, 24), (43871, 24), (113407, 24)] -> (84749, 24)\n",
      "PS_003raw: [(45964, 24), (80000, 24), (61922, 24), (61922, 24), (60502, 24), (43871, 24), (84749, 24)] -> (113407, 24)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_features(locations, sensors):\n",
    "    return list(map(\"\".join, product(locations, sensors)))\n",
    "\n",
    "    \n",
    "def experiment_gen(features, target=\"rule\"):        \n",
    "    for test_trial in dfs.keys():\n",
    "        train_seqs = []\n",
    "        for trial_name, trial_df in dfs.items():\n",
    "            X, y = trial_df.loc[:, features].values, trial_df.loc[:, target].values\n",
    "            if trial_name != test_trial:\n",
    "                train_seqs.append((X, y))\n",
    "            else:\n",
    "                test_seq = (X, y)\n",
    "                \n",
    "        yield test_trial, train_seqs, test_seq\n",
    "        \n",
    "loc_pelvis = [\"Pelvis\"]\n",
    "loc_t8 = [\"T8\"]\n",
    "loc_thighs = [\"LeftThigh\", \"RightThigh\"]\n",
    "\n",
    "sens_q = [\"Orientation_q0\", \"Orientation_q1\", \"Orientation_q2\", \"Orientation_q3\"]\n",
    "sens_euler = [\"Euler_x\", \"Euler_y\", \"Euler_z\"]\n",
    "sens_accel = [\"Accel_X\", \"Accel_Y\", \"Accel_Z\"]\n",
    "sens_gyro = [\"Gyro_x\", \"Gyro_y\", \"Gyro_z\"]\n",
    "\n",
    "\n",
    "#\n",
    "# STUDY CONFIGS\n",
    "# \n",
    "# study_name = \"All\"\n",
    "# study_features = get_features(loc_pelvis + loc_t8 + loc_thighs, sens_q + sens_euler + sens_accel)\n",
    "\n",
    "study_name = \"Raw\"\n",
    "study_features = get_features(loc_pelvis + loc_t8 + loc_thighs, sens_gyro + sens_accel)\n",
    "\n",
    "# study_name = \"No Pelvis\"\n",
    "# study_features = get_features(loc_t8 + loc_thighs, sens_q + sens_euler + sens_accel)\n",
    "\n",
    "# study_name = \"No T8\"\n",
    "# study_features = get_features(loc_pelvis + loc_thighs, sens_q + sens_euler + sens_accel)\n",
    "\n",
    "# study_name = \"No Thighs\"\n",
    "# study_features = get_features(loc_pelvis + loc_t8, sens_q + sens_euler + sens_accel)\n",
    "\n",
    "# study_name = \"Pelvis Only\"\n",
    "# study_features = get_features(loc_pelvis, sens_q + sens_euler + sens_accel)\n",
    "\n",
    "# study_name = \"T8 Only\"\n",
    "# study_features = get_features(loc_t8, sens_q + sens_euler + sens_accel)\n",
    "\n",
    "# study_name = \"Thighs Only\"\n",
    "# study_features = get_features(loc_thighs, sens_q + sens_euler + sens_accel)\n",
    "\n",
    "\n",
    "with redirect_stdout(StringIO()) as info:\n",
    "    print(f\"{study_name = }\")\n",
    "    print(f\"{study_features = }\")\n",
    "    for experiment, train_seqs, test_seq in experiment_gen(study_features):\n",
    "        print(f\"{experiment}: {list(map(lambda s: s[0].shape, train_seqs))} -> {test_seq[0].shape}\")\n",
    "\n",
    "print(info.getvalue())\n",
    "\n",
    "results_dir = Path(\"./results\") / Path(str(dataset_dir.name) + f\" - {study_name}\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(results_dir / \"info.txt\", \"w\") as info_file:\n",
    "    info_file.write(info.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8885ca1-73fe-43e2-b8d9-651c4723c648",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc83a521-17cf-403d-92ee-029bf1ea5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    # X: (<1>, seq, features)\n",
    "    # h0, c0: (num_layers, 1, hidden_size)\n",
    "    # out: (<1>, seq)\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        #self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.reset_hidden()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #out, h0 = self.rnn(x, self.h0)  \n",
    "        # or:\n",
    "        out, (h0, c0) = self.lstm(x, (self.h0, self.c0))\n",
    "        out = self.fc(out)\n",
    "        self.h0, self.c0 = h0.detach(), c0.detach()\n",
    "        return out\n",
    "    \n",
    "    def reset_hidden(self):\n",
    "        self.h0 = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
    "        self.c0 = torch.zeros(self.num_layers, 1, self.hidden_size) \n",
    "\n",
    "# model = RNNModel(train_seqs[0][0].shape[-1], hidden_size=16, num_layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ef2dc1-fcb9-4f72-976e-9e7d7cd35b07",
   "metadata": {},
   "source": [
    "## Build trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381ba893-c2e4-4096-ae46-d1f5f2c924b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train_seqs, num_epochs=50, batch_len=256):\n",
    "    # Model\n",
    "    model = RNNModel(train_seqs[0][0].shape[-1], hidden_size=16, num_layers=2)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    epoch_steps = sum(X.shape[0] for X, _ in train_seqs) // batch_len\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_total_loss = 0\n",
    "        epoch_total_accuracy = 0\n",
    "        epoch_samples = 0\n",
    "        with tqdm(desc=f\"Epoch {epoch}\", total=epoch_steps) as pbar:\n",
    "            for seq_X, seq_y in train_seqs:\n",
    "                model.reset_hidden()\n",
    "                for i in range(0, seq_X.shape[0], batch_len):\n",
    "                    # add dummy batch dimension\n",
    "                    X = torch.from_numpy(seq_X[np.newaxis, i : i + batch_len]).float()\n",
    "                    # add dummy batch and target dimensions\n",
    "                    y = torch.from_numpy(seq_y[np.newaxis, i : i + batch_len, np.newaxis] ).float()\n",
    "                    output = model(X)\n",
    "                    loss = criterion(output, y)\n",
    "\n",
    "                    # Backward and optimize\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    epoch_total_loss += loss.item()\n",
    "                    y_hat = torch.where(output.detach() < 0, 0, 1)\n",
    "                    epoch_total_accuracy += torch.sum(y_hat == y).item()\n",
    "\n",
    "                    epoch_samples += X.shape[1]\n",
    "                    pbar.update()\n",
    "                    if epoch_samples and epoch_samples % 100 == 0:\n",
    "                        pbar.set_postfix(loss=epoch_total_loss/epoch_samples,\n",
    "                                         accuracy=epoch_total_accuracy/epoch_samples)\n",
    "                        \n",
    "    return model\n",
    "\n",
    "#model = build_model(train_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c74e3-b5c7-4252-ba59-30a915c15660",
   "metadata": {},
   "source": [
    "## Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635e34d8-1277-4ab3-ad6b-10bf5a255ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hysteresis(x, th_lo, th_hi):\n",
    "    initial = x[0] > th_hi\n",
    "    hi = x >= th_hi\n",
    "    lo_or_hi = (x <= th_lo) | hi\n",
    "    ind = np.nonzero(lo_or_hi)[0]\n",
    "    if not ind.size: # prevent index error if ind is empty\n",
    "        return np.zeros_like(x, dtype=bool) | initial\n",
    "    cnt = np.cumsum(lo_or_hi) # from 0 to len(x)\n",
    "    return np.where(cnt, hi[ind[cnt-1]], initial)\n",
    "\n",
    "\n",
    "def model_predictions(model, test_seq, batch_len=256):\n",
    "    model.eval()\n",
    "    X, _ = test_seq\n",
    "    with torch.no_grad():\n",
    "        model.reset_hidden()\n",
    "        y = []\n",
    "        for i in range(0, X.shape[0], batch_len):\n",
    "            # add dummy batch dimension\n",
    "            X_batch = torch.from_numpy(X[np.newaxis, i : i + batch_len]).float()\n",
    "            y.append(model(X_batch).view(-1))\n",
    "\n",
    "        soft_preds = torch.sigmoid(torch.cat(y)).numpy()\n",
    "        hard_preds = soft_preds > 0.5\n",
    "        hyst_preds = hysteresis(soft_preds, 0.2, 0.8)\n",
    "\n",
    "    return hard_preds, soft_preds, hyst_preds\n",
    "\n",
    "#hard, soft, hyst = model_predictions(model, test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a98c6e-17ca-4730-8a73-d7f9b5e7d9cc",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af8f492-1435-4e4a-b144-83e47be94cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(experiment, test_seq, hard, soft, hyst):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams['axes.labelsize'] = 16\n",
    "    plt.rcParams['axes.titlesize'] = 18\n",
    "\n",
    "    _, y = test_seq\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(16,10))\n",
    "    \n",
    "    ax = plt.subplot(2, 1, 1)\n",
    "    ax.title.set_text(f\"Clutch Control Timeline: {experiment}\")\n",
    "    \n",
    "    plt.plot(y, \"k\", label=\"Target\");\n",
    "    plt.plot(hard + 0.01, \"b\", label=\"Hard prediction\", alpha=0.3);\n",
    "    plt.plot(soft + 0.02, \"g\", label=\"Soft Predictions\", alpha=0.25);\n",
    "    plt.plot(hyst + 0.03, \"r\", label=\"Hysteresis Predictions\", alpha=0.5);\n",
    "\n",
    "    plt.legend()\n",
    "    plt.yticks([0, 1], [\"off\", \"on\"])\n",
    "    plt.xlabel(\"Time (sample)\")\n",
    "    \n",
    "    \n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "    ax.title.set_text(f\"Hard Predictions: {(y == hard).mean():.2%}\")\n",
    "    cf_matrix = confusion_matrix(y, hard)\n",
    "    f = sns.heatmap(cf_matrix / cf_matrix.sum(), annot=True, fmt='.2%', annot_kws={\"size\": 18})\n",
    "    plt.xlabel(\"Prediction\")\n",
    "    plt.ylabel(\"Target\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 4)\n",
    "    ax.title.set_text(f\"Hysteresis Predictions: {(y == hyst).mean():.2%}\")\n",
    "    cf_matrix = confusion_matrix(y, hyst)\n",
    "    f = sns.heatmap(cf_matrix / cf_matrix.sum(), annot=True, fmt='.2%', annot_kws={\"size\": 18})\n",
    "    plt.xlabel(\"Prediction\")\n",
    "    plt.ylabel(\"Target\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / f\"{experiment}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    result_df = dfs[experiment]\n",
    "    result_df[\"pred_hard\"] = hard.astype(int)\n",
    "    result_df[\"pred_soft\"] = soft\n",
    "    result_df[\"pred_hyst\"] = hyst.astype(int)\n",
    "    result_df.to_csv(results_dir / f\"{experiment}.csv\", index=False)\n",
    "\n",
    "#evaluate(experiment, test_seq, hard, soft, hyst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb927f-2723-4c40-9374-5409793b4f26",
   "metadata": {},
   "source": [
    "## Execute full cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9a8d36-1162-4ca3-9ef9-9e97c0c02362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Experiment: PS_004raw"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "[(80000, 24), (61922, 24), (61922, 24), (60502, 24), (43871, 24), (84749, 24), (113407, 24)] -> (45964, 24)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1981it [02:01, 16.36it/s, accuracy=0.781, loss=0.00199]                          \n",
      "Epoch 1: 1981it [01:55, 17.19it/s, accuracy=0.904, loss=0.00111]                          \n",
      "Epoch 2: 1981it [01:55, 17.18it/s, accuracy=0.845, loss=0.00145]                          \n",
      "Epoch 3: 1981it [01:55, 17.22it/s, accuracy=0.903, loss=0.00105]                          \n",
      "Epoch 4:  98%|█████████▊| 1934/1978 [01:52<00:02, 17.22it/s, accuracy=0.94, loss=0.000764]"
     ]
    }
   ],
   "source": [
    "targets, hards, hysts = [], [], []\n",
    "for experiment, train_seqs, test_seq in experiment_gen(study_features):\n",
    "    display(Markdown(f\"### Experiment: {experiment}\"))\n",
    "    display(Markdown(f\"```\\n{list(map(lambda s: s[0].shape, train_seqs))} -> {test_seq[0].shape}\\n```\"))\n",
    "    \n",
    "    model = build_model(train_seqs)\n",
    "    hard, soft, hyst = model_predictions(model, test_seq)\n",
    "    evaluate(experiment, test_seq, hard, soft, hyst)\n",
    "    targets.append(test_seq[1])\n",
    "    hards.append(hard)\n",
    "    hysts.append(hyst)\n",
    "    \n",
    "target = np.concatenate(targets)\n",
    "hard = np.concatenate(hards)\n",
    "hyst = np.concatenate(hysts)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.title.set_text(f\"Hard Predictions: {(target == hard).mean():.2%}\")\n",
    "cf_matrix = confusion_matrix(target, hard)\n",
    "f = sns.heatmap(cf_matrix / cf_matrix.sum(), annot=True, fmt='.2%', annot_kws={\"size\": 18})\n",
    "plt.xlabel(\"Prediction\")\n",
    "plt.ylabel(\"Target\")\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.title.set_text(f\"Hysteresis Predictions: {(target == hyst).mean():.2%}\")\n",
    "cf_matrix = confusion_matrix(target, hyst)\n",
    "f = sns.heatmap(cf_matrix / cf_matrix.sum(), annot=True, fmt='.2%', annot_kws={\"size\": 18})\n",
    "plt.xlabel(\"Prediction\")\n",
    "plt.ylabel(\"Target\")\n",
    "\n",
    "#plt.title(\"Overall Results\")\n",
    "plt.savefig(results_dir / f\"overall.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea78182-4ce2-4fa4-809f-d0727b579447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpac",
   "language": "python",
   "name": "cpac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
