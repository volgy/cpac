{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-based Experiments with the VTech Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "# Third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Local\n",
    "import utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.load_dataset(f\"s3://cpac/ORIG/VTech/_VTech_merged.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers: 4\n",
      "\tWorker 1: 1 days, 5 trials,  28 transitions,  1,448,215 samples\n",
      "\tWorker 2: 3 days, 4 trials,  68 transitions,  1,351,866 samples\n",
      "\tWorker 3: 1 days, 2 trials,  59 transitions,    859,697 samples\n",
      "\tWorker 4: 1 days, 6 trials, 110 transitions,  1,646,663 samples\n",
      "Total number of transitions: 266.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of workers: {len(df['worker'].unique())}\")\n",
    "for worker, worker_df in df.groupby(\"worker\"):\n",
    "    print(f\"\\tWorker {worker}: {len(worker_df['day'].unique())} days\"\n",
    "          f\", {len(worker_df['trial'].unique())} trials\"\n",
    "          f\", {worker_df['mode'].diff().abs().sum():3.0f} transitions\"\n",
    "          f\", {len(worker_df):10,} samples\")\n",
    "print(f\"Total number of transitions: {df['mode'].diff().abs().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequencing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VTechSeq(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, history, batch_size):\n",
    "        self.df = df\n",
    "        self.history = history\n",
    "        self.batch_size = batch_size\n",
    "        self.trials = []\n",
    "        self.n_seqs = []\n",
    "        \n",
    "        for _, group in df.groupby([\"worker\", \"trial\"]):\n",
    "            trial = group[:-(len(group) % history)]\n",
    "            self.trials.append(trial)\n",
    "            self.n_seqs.append(len(trial) - history + 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(sum(self.n_seqs) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, batch_idx):\n",
    "        batch_features = []\n",
    "        batch_labels = []\n",
    "        for seq_idx in range(self.batch_size * batch_idx , \n",
    "                             self.batch_size * (batch_idx + 1)):\n",
    "            seq_offset = 0\n",
    "            for trial, n_seq in zip(self.trials, self.n_seqs):\n",
    "                trial_seq = seq_idx - seq_offset\n",
    "                if 0 <= trial_seq < n_seq:\n",
    "                    cut = trial.iloc[trial_seq:trial_seq + self.history]\n",
    "                    features = cut.loc[:, \"orientation_T8_q0\":\"jointangles_LeftUpper_z\"].values\n",
    "                    batch_features.append(np.swapaxes(features, 0, 1)[:, np.newaxis, :])\n",
    "                    batch_labels.append(trial.iloc[trial_seq + self.history][\"mode\"])\n",
    "                    break\n",
    "                seq_offset += n_seq\n",
    "                \n",
    "        return np.array(batch_features), np.array(batch_labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = VTechSeq(df, 100, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 6600)              0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 2)                 13202     \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 4)                 16        \n",
      "=================================================================\n",
      "Total params: 13,227\n",
      "Trainable params: 13,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=(seqs[0][0].shape[1:])),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation=\"relu\", name=\"layer1\"),\n",
    "        keras.layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "        keras.layers.Dense(4, name=\"layer3\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = keras.layers.experimental.preprocessing.Normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`generator` must be callable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-a5702394c9b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_generator\u001b[0;34m(generator, output_types, output_shapes, args)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \"\"\"\n\u001b[1;32m    775\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`generator` must be callable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m       output_shapes = nest.map_structure(\n",
      "\u001b[0;31mTypeError\u001b[0m: `generator` must be callable."
     ]
    }
   ],
   "source": [
    "tf.data.Dataset.from_generator(seqs, (tf.dtypes.float64, tf.dtypes.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.54733333333334"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "144821 / 25 / 60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
