{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the CPAC_Insole_Errors datasets\n",
    "\n",
    "- **Model**: Gradient Boosted Trees (histogram-based)\n",
    "- **Target(s)**: `TF_Pelvis_Moment_X_BWBH`, `TF_Pelvis_Moment_Y_BWBH`\n",
    "- **Features**: all, Single IMU (T8)\n",
    "- **Results**: \n",
    "  - $r^2$ scores (by cross-validation)\n",
    "  - feature importances (permutation-based, using the full dataset for training)\n",
    "  - predictions (merged, by cross-validation)\n",
    "- **Evaluation strategy**: cross-validation (leave one subject out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "\n",
    "# Third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.21\", \"Use the conda_python3_latest kernel!\"\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn import (ensemble, metrics, preprocessing, \n",
    "                     pipeline, inspection, model_selection)\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "# Local\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M_Mass</th>\n",
       "      <th>M_Trial_Name</th>\n",
       "      <th>M_Mass_to_L5S1</th>\n",
       "      <th>M_sub_task_indices</th>\n",
       "      <th>M_sub_task_num</th>\n",
       "      <th>M_include_overall</th>\n",
       "      <th>M_Index</th>\n",
       "      <th>M_Sub</th>\n",
       "      <th>M_sub_task_num_overall</th>\n",
       "      <th>M_Index_overall</th>\n",
       "      <th>...</th>\n",
       "      <th>RWRO_03_04_00_00_INSOLE_LX_ML_mm</th>\n",
       "      <th>RWRO_03_04_00_00_INSOLE_LY_AP_mm</th>\n",
       "      <th>RWRO_01_02_00_00_INSOLE_RX_ML_mm</th>\n",
       "      <th>RWRO_01_02_00_00_INSOLE_RY_AP_mm</th>\n",
       "      <th>RWRF_03_00_00_00_INSOLE_LFORCE_BW</th>\n",
       "      <th>RWRF_01_00_00_00_INSOLE_RFORCE_BW</th>\n",
       "      <th>RWRF_03_04_00_00_INSOLE_LX_ML_BH</th>\n",
       "      <th>RWRF_03_04_00_00_INSOLE_LY_AP_BH</th>\n",
       "      <th>RWRF_01_02_00_00_INSOLE_RX_ML_BH</th>\n",
       "      <th>RWRF_01_02_00_00_INSOLE_RY_AP_BH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.0</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.000000</td>\n",
       "      <td>754140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79.464447</td>\n",
       "      <td>9.852873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.882417</td>\n",
       "      <td>3550.709208</td>\n",
       "      <td>5.761006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126216.734765</td>\n",
       "      <td>...</td>\n",
       "      <td>51.508807</td>\n",
       "      <td>119.609160</td>\n",
       "      <td>46.925616</td>\n",
       "      <td>138.942242</td>\n",
       "      <td>0.490595</td>\n",
       "      <td>0.517201</td>\n",
       "      <td>0.027730</td>\n",
       "      <td>0.064395</td>\n",
       "      <td>0.025241</td>\n",
       "      <td>0.074794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.967378</td>\n",
       "      <td>5.134464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322114</td>\n",
       "      <td>2584.089654</td>\n",
       "      <td>2.865929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54239.725770</td>\n",
       "      <td>...</td>\n",
       "      <td>10.399163</td>\n",
       "      <td>55.220508</td>\n",
       "      <td>12.527750</td>\n",
       "      <td>56.781453</td>\n",
       "      <td>0.321761</td>\n",
       "      <td>0.335130</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.029957</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>0.031036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17329.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1451.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92837.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>47.360000</td>\n",
       "      <td>72.550000</td>\n",
       "      <td>42.970000</td>\n",
       "      <td>97.120000</td>\n",
       "      <td>0.195368</td>\n",
       "      <td>0.224205</td>\n",
       "      <td>0.025349</td>\n",
       "      <td>0.039056</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>0.052021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3028.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130544.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52.990000</td>\n",
       "      <td>113.160000</td>\n",
       "      <td>50.330000</td>\n",
       "      <td>140.610000</td>\n",
       "      <td>0.475343</td>\n",
       "      <td>0.500101</td>\n",
       "      <td>0.028589</td>\n",
       "      <td>0.060573</td>\n",
       "      <td>0.026979</td>\n",
       "      <td>0.075169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5189.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168251.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>57.870000</td>\n",
       "      <td>164.170000</td>\n",
       "      <td>54.800000</td>\n",
       "      <td>182.550000</td>\n",
       "      <td>0.761614</td>\n",
       "      <td>0.779576</td>\n",
       "      <td>0.031151</td>\n",
       "      <td>0.088073</td>\n",
       "      <td>0.029594</td>\n",
       "      <td>0.097547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13069.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236897.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>80.310000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>1.422158</td>\n",
       "      <td>1.439392</td>\n",
       "      <td>0.045118</td>\n",
       "      <td>0.151685</td>\n",
       "      <td>0.047191</td>\n",
       "      <td>0.151685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              M_Mass   M_Trial_Name  M_Mass_to_L5S1  M_sub_task_indices  \\\n",
       "count  754140.000000  754140.000000             0.0                 0.0   \n",
       "mean       79.464447       9.852873             NaN                 NaN   \n",
       "std        16.967378       5.134464             NaN                 NaN   \n",
       "min        38.000000       5.000000             NaN                 NaN   \n",
       "25%        79.000000       5.000000             NaN                 NaN   \n",
       "50%        85.000000      10.000000             NaN                 NaN   \n",
       "75%        91.000000      15.000000             NaN                 NaN   \n",
       "max        96.000000      23.000000             NaN                 NaN   \n",
       "\n",
       "       M_sub_task_num  M_include_overall        M_Index          M_Sub  \\\n",
       "count             0.0      754140.000000  754140.000000  754140.000000   \n",
       "mean              NaN           0.882417    3550.709208       5.761006   \n",
       "std               NaN           0.322114    2584.089654       2.865929   \n",
       "min               NaN           0.000000       1.000000       2.000000   \n",
       "25%               NaN           1.000000    1451.000000       4.000000   \n",
       "50%               NaN           1.000000    3028.000000       5.000000   \n",
       "75%               NaN           1.000000    5189.000000       8.000000   \n",
       "max               NaN           1.000000   13069.000000      10.000000   \n",
       "\n",
       "       M_sub_task_num_overall  M_Index_overall  ...  \\\n",
       "count                754140.0    754140.000000  ...   \n",
       "mean                      0.0    126216.734765  ...   \n",
       "std                       0.0     54239.725770  ...   \n",
       "min                       0.0     17329.000000  ...   \n",
       "25%                       0.0     92837.000000  ...   \n",
       "50%                       0.0    130544.000000  ...   \n",
       "75%                       0.0    168251.000000  ...   \n",
       "max                       0.0    236897.000000  ...   \n",
       "\n",
       "       RWRO_03_04_00_00_INSOLE_LX_ML_mm  RWRO_03_04_00_00_INSOLE_LY_AP_mm  \\\n",
       "count                     754140.000000                     754140.000000   \n",
       "mean                          51.508807                        119.609160   \n",
       "std                           10.399163                         55.220508   \n",
       "min                            0.000000                          0.000000   \n",
       "25%                           47.360000                         72.550000   \n",
       "50%                           52.990000                        113.160000   \n",
       "75%                           57.870000                        164.170000   \n",
       "max                           80.310000                        270.000000   \n",
       "\n",
       "       RWRO_01_02_00_00_INSOLE_RX_ML_mm  RWRO_01_02_00_00_INSOLE_RY_AP_mm  \\\n",
       "count                     754140.000000                     754140.000000   \n",
       "mean                          46.925616                        138.942242   \n",
       "std                           12.527750                         56.781453   \n",
       "min                            0.000000                          0.000000   \n",
       "25%                           42.970000                         97.120000   \n",
       "50%                           50.330000                        140.610000   \n",
       "75%                           54.800000                        182.550000   \n",
       "max                           85.000000                        270.000000   \n",
       "\n",
       "       RWRF_03_00_00_00_INSOLE_LFORCE_BW  RWRF_01_00_00_00_INSOLE_RFORCE_BW  \\\n",
       "count                      754140.000000                      754140.000000   \n",
       "mean                            0.490595                           0.517201   \n",
       "std                             0.321761                           0.335130   \n",
       "min                             0.000000                           0.000000   \n",
       "25%                             0.195368                           0.224205   \n",
       "50%                             0.475343                           0.500101   \n",
       "75%                             0.761614                           0.779576   \n",
       "max                             1.422158                           1.439392   \n",
       "\n",
       "       RWRF_03_04_00_00_INSOLE_LX_ML_BH  RWRF_03_04_00_00_INSOLE_LY_AP_BH  \\\n",
       "count                     754140.000000                     754140.000000   \n",
       "mean                           0.027730                          0.064395   \n",
       "std                            0.005661                          0.029957   \n",
       "min                            0.000000                          0.000000   \n",
       "25%                            0.025349                          0.039056   \n",
       "50%                            0.028589                          0.060573   \n",
       "75%                            0.031151                          0.088073   \n",
       "max                            0.045118                          0.151685   \n",
       "\n",
       "       RWRF_01_02_00_00_INSOLE_RX_ML_BH  RWRF_01_02_00_00_INSOLE_RY_AP_BH  \n",
       "count                     754140.000000                     754140.000000  \n",
       "mean                           0.025241                          0.074794  \n",
       "std                            0.006773                          0.031036  \n",
       "min                            0.000000                          0.000000  \n",
       "25%                            0.022911                          0.052021  \n",
       "50%                            0.026979                          0.075169  \n",
       "75%                            0.029594                          0.097547  \n",
       "max                            0.047191                          0.151685  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATASET = \"Compiled_Yinsole_and_T8\"\n",
    "#DATASET_TYPE = \"xlsx\"\n",
    "\n",
    "#DATASET = \"Compiled_SW_and_T8\"\n",
    "#DATASET_TYPE = \"csv\"\n",
    "\n",
    "#DATASET = \"Unadjusted_InsoleY_compiled\"\n",
    "#DATASET_TYPE = \"csv\"\n",
    "\n",
    "#DATASET = \"JustLifts_Compiled_SW_and_T8\"\n",
    "#DATASET_TYPE = \"csv\"\n",
    "\n",
    "#DATASET = \"JustLifts_Compiled_Yinsole_and_T8\"\n",
    "#DATASET_TYPE = \"xlsx\"\n",
    "\n",
    "DATASET = \"JustLifts_Unadjusted_InsoleY_compiled\"\n",
    "DATASET_TYPE = \"csv\"\n",
    "\n",
    "DATASET_S3 = f\"s3://cpac/ORIG/CPAC_Insole_Errors/{DATASET}.{DATASET_TYPE}\"\n",
    "RESULTS_DIR = f\"results/{DATASET}\"\n",
    "\n",
    "\n",
    "df_orig = utils.load_dataset(DATASET_S3)\n",
    "df_orig.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associate column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_columns_with_prefix(df, prefix):\n",
    "    columns = []\n",
    "    for column in df.columns:\n",
    "        if column.startswith(prefix):\n",
    "            columns.append(column)\n",
    "    return columns\n",
    "    \n",
    "def get_target_names(df):\n",
    "    return _get_columns_with_prefix(df, \"T_\")\n",
    "\n",
    "def get_meta_names(df):\n",
    "    return _get_columns_with_prefix(df, \"M_\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up dataset\n",
    "\n",
    "- Remove samples based on `M_include_overall`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 665,466 (before clean-up: 754,140)\n",
      "Number of trials: 4 (before clean-up: 4)\n",
      "Number of subjects: 5\n"
     ]
    }
   ],
   "source": [
    "df = df_orig[df_orig[\"M_include_overall\"] > 0]\n",
    "\n",
    "# Weed out wonky subjects\n",
    "#df = df[df[\"M_Sub\"].isin([2,4,5,6,7,8,9])]\n",
    "#RESULTS_DIR += \"_nowonky\"\n",
    "\n",
    "print(f\"Number of samples: {df.shape[0]:,d} (before clean-up: {df_orig.shape[0]:,d})\")\n",
    "print(f\"Number of trials: {len(df['M_Trial_Name'].unique())} (before clean-up: {len(df_orig['M_Trial_Name'].unique())})\")\n",
    "print(f\"Number of subjects: {len(df['M_Sub'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor configurations (recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All\n",
      "\tPredictors: 25, Sensors: 3\n",
      "\n",
      "Single IMU\n",
      "\tPredictors: 13, Sensors: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predictor_short_name(predictor):\n",
    "    return predictor[17:]\n",
    "\n",
    "def predictor_sensor_number(predictor):\n",
    "    #return int(predictor[5:7])\n",
    "    return predictor[5:7]\n",
    "\n",
    "def filter_predictors(all_predictors, patterns):\n",
    "    if isinstance(patterns, str):\n",
    "        patterns = (patterns,)\n",
    "        \n",
    "    predictors = []\n",
    "    for predictor in all_predictors:\n",
    "        for pattern in patterns:\n",
    "            if pattern in predictor:\n",
    "                predictors.append(predictor)\n",
    "                break\n",
    "    return predictors\n",
    "\n",
    "\n",
    "# def build_feature_sets(df):\n",
    "#     readme_xls = utils.download_dataset(DATASET_README)\n",
    "#     readme = pd.read_excel(readme_xls, sheet_name=\"Recipe_FINAL\")\n",
    "#    \n",
    "#     feature_sets = {}\n",
    "#    \n",
    "#     recipes = readme.iteritems()\n",
    "#     next(recipes)   # first column is bogus\n",
    "#     for recipe_num, recipe in recipes:\n",
    "#         recipe_desc = recipe[3]\n",
    "#         recipe_filter_1 = [filter for filter in (recipe[7], recipe[9]) if isinstance(filter, str)]\n",
    "#         recipe_filter_2 = [filter for filter in recipe[11:] if isinstance(filter, str)]\n",
    "#         recipe_name = f\"Recipe {recipe_num}: {recipe_desc}\"\n",
    "#         feature_sets[recipe_name] = filter_predictors(filter_predictors(df.columns, recipe_filter_1), recipe_filter_2)\n",
    "#    \n",
    "#     return feature_sets\n",
    "\n",
    "#feature_sets = build_feature_sets(df)\n",
    "\n",
    "feature_sets = {\n",
    "    \"All\": df.loc[:, \"RWRF_12_00_00_00_T8_orientation_q1\":].columns,\n",
    "    \"Single IMU\": df.loc[:, \"RWRF_12_00_00_00_T8_orientation_q1\":\"RWRF_12_00_00_00_T8_acceleration_Z_ver\"].columns,\n",
    "}\n",
    "\n",
    "for feature_set_name, predictors in feature_sets.items():\n",
    "    sensors = set(map(predictor_sensor_number, predictors))\n",
    "    print(f\"{feature_set_name}\\n\\tPredictors: {len(predictors)}, Sensors: {len(sensors)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate boosted tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(target_name, feature_names):\n",
    "    X, y, groups = df[feature_names], df[target_name], df[\"M_Sub\"]\n",
    "    \n",
    "    model = pipeline.Pipeline([\n",
    "        ('scaler', preprocessing.StandardScaler()),\n",
    "        ('gboost', ensemble.HistGradientBoostingRegressor())\n",
    "    ])\n",
    "    \n",
    "    logo = model_selection.LeaveOneGroupOut()\n",
    "\n",
    "    prediction = model_selection.cross_val_predict(\n",
    "        model, X, y, cv=logo, groups=groups, n_jobs=-1)\n",
    "\n",
    "    r2_score = {}\n",
    "    for idx_train, idx_test in logo.split(df, groups=groups):\n",
    "        subject = df.iloc[idx_test[0]][\"M_Sub\"]\n",
    "        r2_score[subject] = metrics.r2_score(y.iloc[idx_test], prediction[idx_test])\n",
    "        \n",
    "    r2_score = pd.Series(r2_score)\n",
    "    prediction = pd.Series(prediction, index=y.index)\n",
    "    \n",
    "    # Feature importances on the full training set\n",
    "    model.fit(X, y)\n",
    "    perm_imp = inspection.permutation_importance(model, X, y, n_repeats=5, n_jobs=10)\n",
    "    importance = pd.Series(perm_imp.importances_mean, index=X.columns)\n",
    "    importance.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "    return r2_score, importance, prediction, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments, save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "**Features**: All  \n",
       "**$R^2$ (TO_Pelvis_Moment_X_Nm) = 0.714**\n",
       "**$R^2$ (TO_Pelvis_Moment_Y_Nm) = 0.701**\n",
       "**$R^2$ (TO_Pelvis_Moment_Z_Nm) = -0.502**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "**Features**: Single IMU  \n",
       "**$R^2$ (TO_Pelvis_Moment_X_Nm) = 0.752**\n",
       "**$R^2$ (TO_Pelvis_Moment_Y_Nm) = 0.475**\n",
       "**$R^2$ (TO_Pelvis_Moment_Z_Nm) = -0.243**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "target_name_x = \"TO_Pelvis_Moment_X_Nm\"\n",
    "target_name_y = \"TO_Pelvis_Moment_Y_Nm\"\n",
    "target_name_z = \"TO_Pelvis_Moment_Z_Nm\"\n",
    "\n",
    "\n",
    "r2_mean_scores_x = {}\n",
    "r2_mean_scores_y = {}\n",
    "r2_mean_scores_z = {}\n",
    "\n",
    "\n",
    "for feature_set_name, feature_names in feature_sets.items():\n",
    "    r2_score_x, importance_x, prediction_x, target_x = evaluate(target_name_x, feature_names)\n",
    "    r2_mean_scores_x[feature_set_name] = r2_score_x.mean()\n",
    "    r2_score_y, importance_y, prediction_y, target_y = evaluate(target_name_y, feature_names)\n",
    "    r2_mean_scores_y[feature_set_name] = r2_score_y.mean()\n",
    "    r2_score_z, importance_z, prediction_z, target_z = evaluate(target_name_z, feature_names)\n",
    "    r2_mean_scores_z[feature_set_name] = r2_score_z.mean()\n",
    "    display(\n",
    "        Markdown(\n",
    "            \"---\\n\"\n",
    "            f\"**Features**: {feature_set_name}  \\n\"\n",
    "            f\"**$R^2$ ({target_name_x}) = {r2_mean_scores_x[feature_set_name]:.3f}**\\n\"\n",
    "            f\"**$R^2$ ({target_name_y}) = {r2_mean_scores_y[feature_set_name]:.3f}**\\n\"\n",
    "            f\"**$R^2$ ({target_name_z}) = {r2_mean_scores_z[feature_set_name]:.3f}**\\n\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    with pd.ExcelWriter(f\"{RESULTS_DIR}/R2_scores.xlsx\") as writer:\n",
    "        df_results = pd.DataFrame({f\"R2 - {target_name_x}\": r2_mean_scores_x, \n",
    "                                   f\"R2 - {target_name_y}\": r2_mean_scores_y,\n",
    "                                   f\"R2 - {target_name_z}\": r2_mean_scores_z,})\n",
    "        df_results.to_excel(writer, sheet_name=\"R2 Scores\")\n",
    "\n",
    "\n",
    "    short_name = feature_set_name.split(\":\")[0].replace(\" \", \"_\")\n",
    "    with pd.ExcelWriter(f\"{RESULTS_DIR}/{short_name}_results.xlsx\") as writer:\n",
    "\n",
    "        df_results = pd.DataFrame({f\"R2 - {target_name_x}\": r2_score_x,\n",
    "                                   f\"R2 - {target_name_y}\": r2_score_y,\n",
    "                                   f\"R2 - {target_name_z}\": r2_score_z})\n",
    "        df_results.to_excel(writer, index_label=\"Test Subject\", sheet_name=\"R2 Scores\")\n",
    "\n",
    "\n",
    "        df_results = pd.DataFrame(\n",
    "            {\n",
    "                #\"Short name\": map(predictor_short_name, importance_x.index),\n",
    "                f\"Importance - {target_name_x}\": importance_x,\n",
    "                f\"Importance - {target_name_y}\": importance_y,\n",
    "                f\"Importance - {target_name_z}\": importance_z,\n",
    "            }\n",
    "        )\n",
    "        df_results.to_excel(writer, sheet_name=\"Importance\")\n",
    "        \n",
    "    df_results = pd.DataFrame(\n",
    "        {\n",
    "            f\"Predictions - {target_name_x}\": prediction_x,\n",
    "            f\"Target - {target_name_x}\": target_x,\n",
    "            f\"Predictions - {target_name_y}\": prediction_y,\n",
    "            f\"Target - {target_name_y}\": target_y,\n",
    "            f\"Predictions - {target_name_z}\": prediction_z,\n",
    "            f\"Target - {target_name_z}\": target_z\n",
    "        }\n",
    "    )\n",
    "    df_results.to_csv(f\"{RESULTS_DIR}/{short_name}_predictions.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
